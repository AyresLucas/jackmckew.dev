{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.1 64-bit ('.env')",
   "display_name": "Python 3.8.1 64-bit ('.env')",
   "metadata": {
    "interpreter": {
     "hash": "94acae6b494b26e47a2c1ab0d73ccd231e7e575de7735a2bb644a41097a8ec67"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Building software can be challenging, but maintaining it after that initial build can be even moreso. Being able to test the software such that it verifies the software behaves as expected is crucial in building robust software applications that users depend upon, being able to automate this testing is even better! There's other blog posts on this blog around the topic of testing [Introduction to Pytest & Pipenv](https://jackmckew.dev/introduction-to-pytest-pipenv.html), but for this post we're going to focus on a very specific type of testing, **property based testing**.\n",
    "\n",
    "Property based testing differs itself from the conventional example based testing by being able to generate the test data that drives your tests, and even better, can help find the boundaries of where the tests fail.\n",
    "\n",
    "To demonstrate the power of property based testing, we're going to build some testing for the old faithful multiplication operator in Python.\n",
    "\n",
    "To help with this, we are going to use a few packages:\n",
    "\n",
    "- pytest (testing framework)\n",
    "- hypothesis (property testing package)\n",
    "- ipytest (to enable running tests in jupyter notebooks)\n",
    "\n",
    "Before we dive in, let's set up ipytest and use some **example-based testing** to verify the multiplication operator."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "import pytest\n",
    "ipytest.autoconfig()\n",
    "\n",
    "def multiply(number_1, number_2):\n",
    "    return number_1 * number_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".                                                                        [100%]\n",
      "1 passed in 0.02s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_example():\n",
    "    assert multiply(3,3) == 9\n",
    "    assert multiply(5,5) == 25\n",
    "    assert multiply(4,6) == 24"
   ]
  },
  {
   "source": [
    "Fantastic, our examples passed the test! Now let's ensure that the test fails."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F                                                                        [100%]\n",
      "================================== FAILURES ===================================\n",
      "______________________________ test_fail_example ______________________________\n",
      "\n",
      "    def test_fail_example():\n",
      "        assert multiply(3,3) == 9\n",
      ">       assert multiply(3,5) == 150\n",
      "E       assert 15 == 150\n",
      "E        +  where 15 = multiply(3, 5)\n",
      "\n",
      "<ipython-input-7-212df0aaa8ed>:3: AssertionError\n",
      "=========================== short test summary info ===========================\n",
      "FAILED tmpg6kq2sek.py::test_fail_example - assert 15 == 150\n",
      "1 failed in 0.34s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_fail_example():\n",
    "    assert multiply(3,3) == 9\n",
    "    assert multiply(3,5) == 150"
   ]
  },
  {
   "source": [
    "Perfect! We can see that the test fails as expected and even nicely tells us which line of code it failed on. Let's say we had lots of these examples that we wanted to test for, so to simplify it we could potentially use pytest's **parametrize** decorator."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...                                                                      [100%]\n",
      "3 passed in 0.02s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "@pytest.mark.parametrize('number_1, number_2 , expected', [\n",
    "    (3,3,9),\n",
    "    (5,5,25),\n",
    "    (4,6,24)\n",
    "])\n",
    "def test_multiply(number_1,number_2,expected):\n",
    "    assert expected == multiply(number_1,number_2)"
   ]
  },
  {
   "source": [
    "Is this enough testing to verify our function? Really, we're only testing a few conditions that we'd expect to work, but in reality it's the ones that nobody foresees that would be ideal to capture in our tests. This also raises a few more things, the developer writing the tests may choose to write 2 or 2000 test cases but this doesn't guarantee anything when it comes to if it's truly covered.\n",
    "\n",
    "## Introduce Property Based Testing\n",
    "\n",
    "Property based testing is considered as generative testing, we don't supply specific examples with inputs and expected outputs. Rather we define certain properties and generate randomized inputs to ensure the properties are correct. In addition to this, property based testing can also `shrink` outputs to find the exact boundary condition where a test fails.\n",
    "\n",
    "While this doesn't 100% replace example-based testing, they definitely have their use and have a lot of potential for effective testing. Now let's implement the same tests above, using property based testing with `hypothesis`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypothesis import given\n",
    "import hypothesis.strategies as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".                                                                        [100%]\n",
      "1 passed in 0.14s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "@given(st.integers(),st.integers())\n",
    "def test_multiply(number_1,number_2):\n",
    "    assert multiply(number_1,number_2) == number_1 * number_2"
   ]
  },
  {
   "source": [
    "Note that we've used the `given` decorator which makes our test parametrized, and use strategies which cover the types of input data to generate. As per the hypothesis documentation *Most things should be easy to generate and everything should be possible*, we can find more information on them here: <https://hypothesis.readthedocs.io/en/latest/data.html>\n",
    "\n",
    "Now this doesn't look any different to last time, so what even changed! Let's change our multiply function so it behaves strangely and see if we can see hypothesis shrink the failures in action. Shrinking is whenever it finds a failure, it'll try to get to the absolute boundary case to help us find the potential cause and even better it'll remember this failure for next time so it doesn't poke it's head up again!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_multiply(number_1,number_2):\n",
    "    if number_1 > 30:\n",
    "        return 0\n",
    "    if number_2 < 0:\n",
    "        return 0\n",
    "    return number_1 * number_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F                                                                        [100%]\n",
      "================================== FAILURES ===================================\n",
      "______________________________ test_bad_multiply ______________________________\n",
      "\n",
      "    @given(st.integers(),st.integers())\n",
      ">   def test_bad_multiply(number_1,number_2):\n",
      "\n",
      "<ipython-input-16-3e2ec463c8ad>:2: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "number_1 = 31, number_2 = 1\n",
      "\n",
      "    @given(st.integers(),st.integers())\n",
      "    def test_bad_multiply(number_1,number_2):\n",
      ">       assert bad_multiply(number_1,number_2) == number_1 * number_2\n",
      "E       assert 0 == (31 * 1)\n",
      "E        +  where 0 = bad_multiply(31, 1)\n",
      "\n",
      "<ipython-input-16-3e2ec463c8ad>:3: AssertionError\n",
      "--------------------------------- Hypothesis ----------------------------------\n",
      "Falsifying example: test_bad_multiply(\n",
      "    number_1=31, number_2=1,\n",
      ")\n",
      "=========================== short test summary info ===========================\n",
      "FAILED tmp8uis7_kv.py::test_bad_multiply - assert 0 == (31 * 1)\n",
      "1 failed in 0.22s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "@given(st.integers(),st.integers())\n",
    "def test_bad_multiply(number_1,number_2):\n",
    "    assert bad_multiply(number_1,number_2) == number_1 * number_2"
   ]
  },
  {
   "source": [
    "Fantastic, we can see that the failure has been shrunken to `number_1` being 31 and `number_2` being 1 which is one integer off the 'bad' boundary conditions we'd introduced into the multiply function.\n",
    "\n",
    "Hopefully this has introduced the power of property based testing and can help make software more robust for everyone!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}